@[TOC](半监督节点分类：标签传播和信息传递)
# 1 导论
## 1.1 求解方法对比
半监督节点分类：用已知标签节点预测未知标签的节点
**求解思路**：
 1. 节点特征工程 
 2. 节点表示学习：端到端的表示学习
 3.  标签传播（消息传递）
 4. 图神经网络
![在这里插入图片描述](https://img-blog.csdnimg.cn/d45ea9c0d8ac4c8d971e81c39fa8552f.png)
## 1.2 直推式学习与归纳式学习

直推式学习：未知标签的节点可能被用于训练，但过程中没有新节点加入，不需要对新节点进行泛化，不需要进行新节点的预测；
与之相反的是inductive learning，归纳式学习：对新节点立刻进行预测，可以泛化到新节点

![在这里插入图片描述](https://img-blog.csdnimg.cn/82d3bc9fa59140ce82a6ccdd53b7f804.png)
## 1.3 半监督节点分类任务

![在这里插入图片描述](https://img-blog.csdnimg.cn/c9476cc35fb04a7ab8ca66d3de5429de.png)
已知：
部分节点有标签，0和1；部分节点无标签
每个节点有一个属性特征向量
预测：无标签节点属于1和0的概率
![在这里插入图片描述](https://img-blog.csdnimg.cn/411d4f2bf5be42e991f543338dbfead8.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/6f81dc3bba974155bb4fbeb586b2ee1b.png)
许多应用可以基于这个模型
![在这里插入图片描述](https://img-blog.csdnimg.cn/ed0660de952f4637a4de77db7e64485a.png)
## 1.4 方法
### 1.4.1 两种关联
![在这里插入图片描述](https://img-blog.csdnimg.cn/e5ccc61690334d77afc7f309f850a0ba.png)
#### a. Homophily
具有相似属性特征的节点更可能相连且有相同的类别
![在这里插入图片描述](https://img-blog.csdnimg.cn/090bdca3196f4ad2ac0385eb4a63831a.png)
举例：高中生社团，节点颜色表示对不同的领域感兴趣
![在这里插入图片描述](https://img-blog.csdnimg.cn/2e802b94f8bd45f194b4e59cfe8d270f.png)
#### b.  Influence
社交关系会影响节点类别
![在这里插入图片描述](https://img-blog.csdnimg.cn/aeb5dab181ac4de6aebc9064843b6604.png)
## 1.4.2 五种方法
如何利用两种关联？：KNN最近邻分类
![在这里插入图片描述](https://img-blog.csdnimg.cn/805c4e7c4d4a4bbcaaf0f8e7082da1fd.png)
前两种属于集体分类
三属于一种后处理技术
四属于消息传递
五属于一种自监督学习
![在这里插入图片描述](https://img-blog.csdnimg.cn/8b3ec19f477640da83b4787e3b617416.png)
# 2 label propagation
仅使用网络连接特征
## 2.1 初始化
已知标签为1和0，未知标签设为0.5
![在这里插入图片描述](https://img-blog.csdnimg.cn/776ca2b5dc184a7e883d29888f42d5d7.png)
## 2.2 迭代计算
第一次迭代：
周围节点标签求平均值
![在这里插入图片描述](https://img-blog.csdnimg.cn/06552668a4c446b8921d7f9d430f2824.png)
第四次迭代
![在这里插入图片描述](https://img-blog.csdnimg.cn/600f0c93f0524552a6ff61f2c161b0d4.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/76df19ee8ff54385840e81d50d662d98.png)
## 2.3 小结
周围节点标签求平均值，迭代计算
**缺点**：
不保证收敛
仅用到网络连接信息，没有用到节点属性信息
![在这里插入图片描述](https://img-blog.csdnimg.cn/6a7356ec0eca4004ac98554cb685698f.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/627f6a7f173b402dad5a1833339ff21d.png)
# 3 iterative classification
## 3.1 步骤
训练两个分类器：
base classifier：Φ1仅使用节点属性特征
relational classifier：Φ2使用节点属性特征和网络连接特征
![在这里插入图片描述](https://img-blog.csdnimg.cn/9de6b428a1f44e219718cf1d1e1b2ea8.png)
Zv是包含邻域节点类别信息的向量，n维向量代表了这个节点的连接信息
可以自定义：
 1. 周围不同节点类别的个数（绿色节点有多少，红色节点有多少）
 2. 附近数量最多的类别是什么（附近绿色节点多还是红色节点多）
 3. 有多少个不同的类别
**标注好的训练集**
使用已标注数据训练两个分类器
**没有标签的训练集**
用训练好的Φ1预测位置类别的Yv（类别向量）
用Yv计算Zv
用Φ2预测所有节点类别
重复：重新计算Zv，重新预测Yv
![在这里插入图片描述](https://img-blog.csdnimg.cn/15f728bb4c97486fa13dab8f15805996.png)
## 3.2 举例：
![在这里插入图片描述](https://img-blog.csdnimg.cn/e4333e8ed2304389abe3a413a628d237.png)
第一步：用已有标签节点的属性特征向量训练一个Φ1
![在这里插入图片描述](https://img-blog.csdnimg.cn/35b47598fa39432abe13693e4bd67206.png)
第二步：构造Zv,训练Φ2
![在这里插入图片描述](https://img-blog.csdnimg.cn/b662a81a1bce4af0a3a85e7f5f9b9131.png)
第三步：先用Φ1在未知节点上进行一次预测，得到标签Y
![在这里插入图片描述](https://img-blog.csdnimg.cn/5270ba47d982482085cf870bd9c80a34.png)
第四步迭代：
更新Zv
更新Yv
![在这里插入图片描述](https://img-blog.csdnimg.cn/e1d8d635dedb44328b0624f568467d17.png)
第五步：停止迭代
![在这里插入图片描述](https://img-blog.csdnimg.cn/82c81e0106224cedb739ca19e4e866a0.png)
## 3.3 小结
基本假设：马尔科夫假设
我的类别取决于与我相连的节点的类别，与我邻居的邻居没有关系
![在这里插入图片描述](https://img-blog.csdnimg.cn/88586617f50047a2a5b324d799ceb68e.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/13cc214c513a4016b1c31bef70e16a09.png)
# 4 correct&smooth
不属于collective classification，属于一种后处理技术
![在这里插入图片描述](https://img-blog.csdnimg.cn/964f1a95e09d47c0b43d8c980ebafa85.png)
第一步：在已经有标签的节点上训练模型
![在这里插入图片描述](https://img-blog.csdnimg.cn/ee72c3175d3944ba9d94041e41685eb4.png)
第二步：用训练好的模型对所有的节点进行预测，预测结果并不是非0即1的，而是概率值
![在这里插入图片描述](https://img-blog.csdnimg.cn/1a899e21530e4bf3b6620bd84d7c53dc.png)第三步：后处理correct&smooth
correct：让模型对不确定程度进行扩散
smooth：让最终的预测结果变得平滑
## 4.1correct：
![在这里插入图片描述](https://img-blog.csdnimg.cn/6aa309c3aec64c1ba73844d0cea26270.png)
只计算有标注的节点
![在这里插入图片描述](https://img-blog.csdnimg.cn/b4923a8652ae4fd1afda17c5f068274e.png)
得到error矩阵，
![在这里插入图片描述](https://img-blog.csdnimg.cn/bcd83ea836f5468a96dd2bddb11a8e27.png)
di表示第i个节点的度
![在这里插入图片描述](https://img-blog.csdnimg.cn/7b4a5e58a6d545c8918249ed9ff953ac.png)
归一化扩散矩阵有以下好处：
特征值在（-1，1）之间，不会发三
当特征值为1时，特征向量为D^0.5*1（这里的1是一个向量）
![在这里插入图片描述](https://img-blog.csdnimg.cn/6db706b895814c1da4e18e25e29aa8b2.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/213e952af9054fb9b80395b9bac3537a.png)
迭代计算误差矩阵
α越大表示更愿意相信传播来的error，否则更相信原来的error
![在这里插入图片描述](https://img-blog.csdnimg.cn/492b9a6259d548cebf1c10889ac1bb1f.png)
s是超参数
![在这里插入图片描述](https://img-blog.csdnimg.cn/febb5ed0f28c4ada95552d8e3e826eab.png)
## 4.2 smooth
![在这里插入图片描述](https://img-blog.csdnimg.cn/17cb794ce62e4c2fa6af3ab6bc597180.png)
对置信度（最终的预测结果）进行传播
![在这里插入图片描述](https://img-blog.csdnimg.cn/802728a8a3024da786700f4be5f84d61.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/5be87e8afddc437ebace0fed43cc02a1.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/f7a0b03736d44351817e3a369521a065.png)
##  4.3 小结
![在这里插入图片描述](https://img-blog.csdnimg.cn/42de7a411fd74e5ab22fa35382968d44.png)
# 5 Loopy belief propagation
节点之间可以传消息
这一时刻的状态仅取决于上一时刻的状态
当所有的节点达成共识时，就得到了最终的预测结果
![在这里插入图片描述](https://img-blog.csdnimg.cn/2f50633702024e70897df567199a6045.png)
## 5.1 消息传递
报数
![在这里插入图片描述](https://img-blog.csdnimg.cn/190a21f48cd74f8ba2c5774061e76dbb.png)
树状图
从下级逐级向上级汇报
![在这里插入图片描述](https://img-blog.csdnimg.cn/009d8278c72f4cbea3149b398eb2cb32.png)
## 5.2 定义
![在这里插入图片描述](https://img-blog.csdnimg.cn/4b4691e0c4794c4495a3088ad267407e.png)
## 5.3 步骤
![在这里插入图片描述](https://img-blog.csdnimg.cn/e5363cfd863047bfadff48e77ac9d0ba.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/cd0e73377586484e8438d17d5200ca90.png)
## 5.4 问题
当图中有环时？
消息不再是独立的
![在这里插入图片描述](https://img-blog.csdnimg.cn/7c133e8a4d2f41cfa60629ef8d9b6586.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/77b809f350a3474cb599cfae01e92a7d.png)
## 5.5 总结
易编程和并行
不保证收敛
需要训练参数优化得到
![在这里插入图片描述](https://img-blog.csdnimg.cn/d2598042c8434736a544ae8f6827e895.png)
# 6 masked label prediction
bert:语言模型，把中间词扣掉，让周围词去预测
![在这里插入图片描述](https://img-blog.csdnimg.cn/ebb8d2ea09f4440ab03f2c597c646635.png)
随机把一些节点的label设为0，尝试用已有信息的label，猜出这些节点的label；进而构造自监督模型，迭代优化
![在这里插入图片描述](https://img-blog.csdnimg.cn/85976de18cca4851b38cdd925451fe4f.png)








































